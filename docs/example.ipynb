{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook\n",
    "\n",
    "This notebook will cover a regression case using scikit-learn's *California Housing* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "X, y = fetch_california_housing(data_home='miraiml_local', return_X_y=True)\n",
    "data = pd.DataFrame(X)\n",
    "data['target'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training and testing data. In a real case scenario, we'd only have labels for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the search spaces\n",
    "\n",
    "Let's compare (and ensemble) a `KNeighborsRegressor` and a pipeline composed by `StandardScaler` and a `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from miraiml import SearchSpace\n",
    "from miraiml.pipeline import compose\n",
    "\n",
    "Pipeline = compose(\n",
    "    [('scaler', StandardScaler), ('lin_reg', LinearRegression)]\n",
    ")\n",
    "\n",
    "search_spaces = [\n",
    "    SearchSpace(\n",
    "        id='k-NN Regressor',\n",
    "        model_class=KNeighborsRegressor,\n",
    "        parameters_values=dict(\n",
    "            n_neighbors=range(2, 9),\n",
    "            weights=['uniform', 'distance'],\n",
    "            p=range(2, 5)\n",
    "        )\n",
    "    ),\n",
    "    SearchSpace(\n",
    "        id='Pipeline',\n",
    "        model_class=Pipeline,\n",
    "        parameters_values=dict(\n",
    "            scaler__with_mean=[True, False],\n",
    "            scaler__with_std=[True, False],\n",
    "            lin_reg__fit_intercept=[True, False]\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Engine\n",
    "\n",
    "For this test, let's use `r2_score` to evaluate our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from miraiml import Config\n",
    "\n",
    "config = Config(\n",
    "    local_dir='miraiml_local',\n",
    "    problem_type='regression',\n",
    "    score_function=r2_score,\n",
    "    search_spaces=search_spaces,\n",
    "    ensemble_id='Ensemble'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggering the Engine\n",
    "\n",
    "Let's also print the scores everytime the Engine finds a better solution for any base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miraiml import Engine\n",
    "\n",
    "def on_improvement(status):\n",
    "    scores = status.scores\n",
    "    for key in sorted(scores.keys()):\n",
    "        print('{}: {}'.format(key, round(scores[key], 3)), end='; ')\n",
    "    print()\n",
    "\n",
    "engine = Engine(config=config, on_improvement=on_improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.load_train_data(train_data, 'target')\n",
    "engine.load_test_data(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leave it running for 2 minutes and then interrupt it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "engine.restart()\n",
    "\n",
    "sleep(120)\n",
    "\n",
    "engine.interrupt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = engine.request_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the status report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(status.build_report(include_features=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the k-NN Regressor's score changes with `n_neighbors`, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "knn_history = status.histories['k-NN Regressor']\n",
    "\n",
    "knn_history\\\n",
    ".groupby('n_neighbors__(hyperparameter)').mean()\\\n",
    ".reset_index()[['n_neighbors__(hyperparameter)', 'score']]\\\n",
    ".plot.scatter(x='n_neighbors__(hyperparameter)', y='score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, in practice we wouldn't have labels for `test_data`, but how would the Engine perform on the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(test_data['target'], status.test_predictions['Ensemble'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
